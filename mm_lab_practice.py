# -*- coding: utf-8 -*-
"""MM_Lab_Practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mOdB8W8aKZNjPXBVVTD5B_my8u-d9XGM
"""

import sympy as sp
import matplotlib.pyplot as plt
from tabulate import tabulate
from scipy.stats import ttest_ind
import numpy as np

def f(x, y):
    return x - 2*y

def euler(f, x0, y0, h, n):
    x_vals, y_vals = [x0], [y0]
    for _ in range(n):
        x_curr, y_curr = x_vals[-1], y_vals[-1]
        x_next = round(x_curr + h, 2)
        y_next = y_curr + h * f(x_curr, y_curr)
        x_vals.append(x_next)
        y_vals.append(y_next)
    return x_vals, y_vals

def runge_kutta(f, x0, y0, h, n):
    x_vals, y_vals = [x0], [y0]
    for _ in range(n):
        x_curr, y_curr = x_vals[-1], y_vals[-1]
        x_next = round(x_curr + h, 2)
        k1 = h * f(x_curr, y_curr)
        k2 = h * f(x_curr + h/2, y_curr + k1/2)
        k3 = h * f(x_curr + h/2, y_curr + k2/2)
        k4 = h * f(x_curr + h, y_curr + k3)
        y_next = y_curr + (1/6)*(k1 + 2*k2 + 2*k3 + k4)
        x_vals.append(x_next)
        y_vals.append(y_next)
    return x_vals, y_vals

def milne_method(f, x_init, y_init, h, n_total):
    x_vals = x_init.copy()
    y_vals = y_init.copy()
    for i in range(3, n_total):
        x_pred = round(x_vals[i] + h, 2)
        y_pred = y_vals[i-3] + (4*h/3)*(2*f(x_vals[i-2], y_vals[i-2]) - f(x_vals[i-1], y_vals[i-1]) + 2*f(x_vals[i], y_vals[i]))
        y_corr = y_vals[i-1] + (h/3)*(f(x_vals[i-1], y_vals[i-1]) + 4*f(x_vals[i], y_vals[i]) + f(x_pred, y_pred))
        x_vals.append(x_pred)
        y_vals.append(y_corr)
    return x_vals, y_vals

def monte_carlo_method(f, x_vals, y0, n_sim=1000):
    y_vals = [y0]
    for i in range(1, len(x_vals)):
        y_samples = [y_vals[-1] + (x_vals[i] - x_vals[i-1]) * f(np.random.uniform(x_vals[i-1], x_vals[i]), y_vals[-1]) for _ in range(n_sim)]
        y_vals.append(np.mean(y_samples))
    return y_vals

def newton_divided_difference(x_points, y_points):
    n = len(x_points)
    F = [[0] * n for _ in range(n)]
    for i in range(n):
        F[i][0] = y_points[i]

    for j in range(1, n):
        for i in range(n - j):
            F[i][j] = (F[i+1][j-1] - F[i][j-1]) / (x_points[i+j] - x_points[i])

    def newton_poly(x):
        result = F[0][0]
        product = 1
        for j in range(1, n):
            product *= (x - x_points[j-1])
            result += F[0][j] * product
        return result

    return newton_poly

# Initial Setup
x0, y0, h, n = 0, 1, 0.1, 20

# Exact solution
x = sp.Symbol('x')
y = sp.Function('y')(x)
diffeq = sp.Eq(y.diff(x), x - 2*y)
sol = sp.dsolve(diffeq, y)
C1 = sp.Symbol('C1')
C1_val = sp.solve(sp.Eq(sol.rhs.subs(x, x0), y0), C1)[0]
exact = sol.subs(C1, C1_val)
y_exact_fn = sp.lambdify(x, exact.rhs, 'numpy')

# Numerical Methods
x_euler, y_euler = euler(f, x0, y0, h, n)
x_rk, y_rk = runge_kutta(f, x0, y0, h, n)
x_milne, y_milne = milne_method(f, x_rk[:4], y_rk[:4], h, n+1)
y_monte = monte_carlo_method(f, x_euler, y0)
y_exact = [y_exact_fn(xi) for xi in x_euler]

# Newton's Divided Difference Interpolation using first 6 RK points
x_rk_6 = x_rk[:6]
y_rk_6 = y_rk[:6]
newton_poly = newton_divided_difference(x_rk_6, y_rk_6)
y_newton = [newton_poly(xi) for xi in x_euler]

# Tables
table_euler = [[i, x_euler[i], round(y_euler[i], 5), round(y_exact[i], 5)] for i in range(n+1)]
print("\nEuler Method Table:\n")
print(tabulate(table_euler, headers=["Step", "x", "y (Euler)", "Exact y"], tablefmt="fancy_grid"))

table_rk = [[i, x_rk[i], round(y_rk[i], 5), round(y_exact[i], 5)] for i in range(n+1)]
print("\nRunge Kutta Method Table:\n")
print(tabulate(table_rk, headers=["Step", "x", "y (RK)", "Exact y"], tablefmt="fancy_grid"))

table_milne = [[i, x_milne[i], round(y_milne[i], 5), round(y_exact[i], 5)] for i in range(n+1)]
print("\nMilne Method Table:\n")
print(tabulate(table_milne, headers=["Step", "x", "y (Milne)", "Exact y"], tablefmt="fancy_grid"))

table_mc = [[i, x_euler[i], round(y_monte[i], 5), round(y_exact[i], 5)] for i in range(n+1)]
print("\nMonte Carlo Method Table:\n")
print(tabulate(table_mc, headers=["Step", "x", "y (Monte Carlo)", "Exact y"], tablefmt="fancy_grid"))

table_newton = [[i, x_euler[i], round(y_newton[i], 5), round(y_exact[i], 5)] for i in range(n+1)]
print("\nNewton's Divided Difference Interpolation Table:\n")
print(tabulate(table_newton, headers=["Step", "x", "y (Newton)", "Exact y"], tablefmt="fancy_grid"))

# Combined Comparison Table
table = [[i, round(x_euler[i], 2), round(y_euler[i], 5), round(y_rk[i], 5), round(y_milne[i], 5), round(y_monte[i], 5), round(y_newton[i], 5), round(y_exact[i], 5)] for i in range(n+1)]
print("\nCombined Comparison Table:\n")
print(tabulate(table, headers=["Step", "x", "Euler", "RK4", "Milne", "Monte Carlo", "Newton", "Analytical"], tablefmt="fancy_grid"))

# Plot
plt.figure(figsize=(10, 6))
plt.plot(x_euler, y_exact, label="Analytical", linewidth=3)
plt.plot(x_euler, y_euler, label="Euler", linestyle='--', marker='o')
plt.plot(x_rk, y_rk, label="RK4", linestyle='-.', marker='^')
plt.plot(x_milne, y_milne, label="Milne", linestyle=':', marker='s')
plt.plot(x_euler, y_monte, label="Monte Carlo", linestyle='--', marker='x')
# plt.plot(x_euler, y_newton, label="Newton", linestyle='-', marker='d')
plt.grid(True)
plt.xlabel("x")
plt.ylabel("y")
plt.title("Comparison of Numerical Methods with Newton's Interpolation")
plt.legend()
plt.tight_layout()
plt.show()

# T-Test
print("\nT-Test Results:\n")
def print_ttest(name, y_pred, y_actual):
    t_result = ttest_ind(y_pred, y_actual)
    print(f"{name} vs Analytical:\n   t-stat = {t_result.statistic:.5f}, p = {t_result.pvalue:.5f}")
    print("   =>", "Significant difference" if t_result.pvalue < 0.05 else "No significant difference", "\n")

print_ttest("Euler", np.array(y_euler), np.array(y_exact))
print_ttest("RK4", np.array(y_rk), np.array(y_exact))
print_ttest("Milne", np.array(y_milne[:len(y_exact)]), np.array(y_exact))
print_ttest("Monte Carlo", np.array(y_monte), np.array(y_exact))
print_ttest("Newton", np.array(y_newton), np.array(y_exact))

#Q1)

import numpy as np
import matplotlib.pyplot as plt

N_values = [2, 4, 6, 8, 12, 20]

x = np.linspace(-1, 1, 400)

def divided_diff(x, y):
    n = len(y)
    coef = y.copy()
    for j in range(1, n):
        for i in range(n-1, j-1, -1):
            coef[i] = (coef[i] - coef[i-1]) / (x[i] - x[i-j])
    return coef

def newton_poly(x, x_points, coef):
    n = len(x_points) - 1
    result = coef[n]
    for i in range(n-1, -1, -1):
        result = result * (x - x_points[i]) + coef[i]
    return result

# Function to construct p_2N(x) using Newton's divided difference

def construct_p2N(N):
    x_points = [0] + [j/N for j in range(1, N+1)] + [-j/N for j in range(1, N+1)]
    y_points = [1] + [0] * (2 * N)  # p(0) = 1, others = 0
    coef = divided_diff(x_points, y_points)
    return lambda x: newton_poly(x, x_points, coef)

# Plot for each N
for N in N_values:
    p2N = construct_p2N(N)
    plt.plot(x, [p2N(xi) for xi in x], label=f'N = {N}', color='purple')

    plt.xlabel('x')
    plt.ylabel('p_2N(x)')
    plt.title('Polynomial Interpolation for N = {0}'.format(N))
    plt.legend()
    plt.grid(True)
    plt.show()
    print("\n")

print("\n\n")
print("Interpretation:\n")
print("As N increases, the polynomial p_2N(x) exhibits more pronounced oscillations, \nparticularly near the endpoints x = Â±1. \nThis is indicative of Runge's phenomenon, where higher-degree polynomials used for interpolation \n over an interval can lead to large oscillations and poor approximation outside the data points.")

#Q2)

import numpy as np
import matplotlib.pyplot as plt

# Standard normal distribution function
def f(x):
    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x**2)

# True value of P(Z < 2)
true_value = 0.977249868051821

a, b = -10, 2

# Trapezoidal rule implementation
def trapezoidal_rule(a, b, n):
    x = np.linspace(a, b, n)
    y = f(x)
    h = (b - a) / (n - 1)
    integral = (h / 2) * (y[0] + 2 * np.sum(y[1:-1]) + y[-1])
    return integral, x, y

# Simpson's rule implementation
def simpsons_rule(a, b, n):
    if n % 2 == 0:
        n += 1  # Ensure odd number of points
    x = np.linspace(a, b, n)
    y = f(x)
    h = (b - a) / (n - 1)
    integral = (h / 3) * (y[0] + y[-1] + 4 * np.sum(y[1:-1:2]) + 2 * np.sum(y[2:-2:2]))
    return integral, x, y

# Compute results for 2001 points
n1 = 2001
trap_result1, x_trap1, y_trap1 = trapezoidal_rule(a, b, n1)
simp_result1, x_simp1, y_simp1 = simpsons_rule(a, b, n1)

# Compute results for 4001 points
n2 = 4001
trap_result2, x_trap2, y_trap2 = trapezoidal_rule(a, b, n2)
simp_result2, x_simp2, y_simp2 = simpsons_rule(a, b, n2)

print(f"Trapezoidal Rule (2001 points): {trap_result1:.8f}")
print(f"Simpson's Rule (2001 points): {simp_result1:.8f}")
print(f"Trapezoidal Rule (4001 points): {trap_result2:.8f}")
print(f"Simpson's Rule (4001 points): {simp_result2:.8f}")

# Visualization
plt.figure(figsize=(15, 10))

# Plot 1: Function and Trapezoidal Approximation (2001 points)
plt.subplot(2, 2, 1)
plt.plot(x_trap1, y_trap1, label='f(x)', color='blue')
for i in range(len(x_trap1)-1):
    plt.fill_between([x_trap1[i], x_trap1[i+1]], [0, 0], [y_trap1[i], y_trap1[i+1]], color='lightgreen', alpha=0.3)
plt.title('Trapezoidal Rule Approximation (2001 points)')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.legend()

# Plot 2: Function and Simpson's Approximation (2001 points)
plt.subplot(2, 2, 2)
plt.plot(x_simp1, y_simp1, label='f(x)', color='blue')
x_mid = (x_simp1[:-1] + x_simp1[1:]) / 2
y_mid = f(x_mid)
for i in range(0, len(x_simp1)-2, 2):
    plt.fill_between([x_simp1[i], x_simp1[i+2]], [0, 0], [y_simp1[i], y_simp1[i+2]], color='skyblue', alpha=0.3, interpolate=True)
plt.title("Simpson's Rule Approximation (2001 points)")
plt.xlabel('x')
plt.ylabel('f(x)')
plt.legend()

# Plot 3: Function and Trapezoidal Approximation (4001 points)
plt.subplot(2, 2, 3)
plt.plot(x_trap2, y_trap2, label='f(x)', color='blue')
for i in range(len(x_trap2)-1):
    plt.fill_between([x_trap2[i], x_trap2[i+1]], [0, 0], [y_trap2[i], y_trap2[i+1]], color='lightgreen', alpha=0.3)
plt.title('Trapezoidal Rule Approximation (4001 points)')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.legend()

# Plot 4: Function and Simpson's Approximation (4001 points)
plt.subplot(2, 2, 4)
plt.plot(x_simp2, y_simp2, label='f(x)', color='blue')
x_mid = (x_simp2[:-1] + x_simp2[1:]) / 2
y_mid = f(x_mid)
for i in range(0, len(x_simp2)-2, 2):
    plt.fill_between([x_simp2[i], x_simp2[i+2]], [0, 0], [y_simp2[i], y_simp2[i+2]], color='skyblue', alpha=0.3, interpolate=True)
plt.title("Simpson's Rule Approximation (4001 points)")
plt.xlabel('x')
plt.ylabel('f(x)')
plt.legend()

plt.tight_layout()
plt.show()

# Convergence comment
print("\nConvergence behavior: Both the trapezoidal and Simpson's rules approximate the\n integral better with an increase from 2001 to 4001 points.\n Simpson's rule, being a higher-order method (O(h^4)),\n shows faster convergence and a closer approximation to the\n true value compared to the trapezoidal rule (O(h^2)), especially noticeable with the finer grid.")

#Q3)

import numpy as np
import matplotlib.pyplot as plt

def f(x):
    return np.sin(x)

exact_value = 1 - np.cos(5)  # â«sin(x)dx from 0 to 5

# Composite Trapezoidal Rule
def composite_trapezoidal(a, b, n):
    x = np.linspace(a, b, n+1)
    y = f(x)
    h = (b - a) / n
    integral = (h / 2) * (y[0] + 2 * np.sum(y[1:-1]) + y[-1])
    return integral, x, y

# Composite Simpson's Rule
def composite_simpsons(a, b, n):
    if n % 2 != 0:
        n += 1  # Ensure even number of subintervals
    x = np.linspace(a, b, n+1)
    y = f(x)
    h = (b - a) / n
    integral = (h / 3) * (y[0] + y[-1] + 4 * np.sum(y[1:-1:2]) + 2 * np.sum(y[2:-2:2]))
    return integral, x, y

a, b = 0, 5
n = 20        # Number of subintervals

# Computing integrals
trap_result, x_trap, y_trap = composite_trapezoidal(a, b, n)
simp_result, x_simp, y_simp = composite_simpsons(a, b, n)

# Computing absolute errors
trap_error = abs(exact_value - trap_result)
simp_error = abs(exact_value - simp_result)

# Printing results
print(f"Exact Value: {exact_value:.8f}")
print(f"Composite Trapezoidal Rule (20 subintervals): {trap_result:.8f}, Absolute Error: {trap_error:.8f}")
print(f"Composite Simpson's Rule (20 subintervals): {simp_result:.8f}, Absolute Error: {simp_error:.8f}")

# Visualization
plt.figure(figsize=(12, 5))

# Plot 1: Function and Trapezoidal Approximation
plt.subplot(1, 2, 1)
plt.plot(x_trap, y_trap, label='sin(x)', color='blue')
for i in range(len(x_trap)-1):
    plt.fill_between([x_trap[i], x_trap[i+1]], [0, 0], [y_trap[i], y_trap[i+1]], color='red', alpha=0.3)
plt.title('Composite Trapezoidal Rule (20 subintervals)')
plt.xlabel('x')
plt.ylabel('sin(x)')
plt.legend()

# Plot 2: Function and Simpson's Approximation
plt.subplot(1, 2, 2)
plt.plot(x_simp, y_simp, label='sin(x)', color='blue')
for i in range(0, len(x_simp)-2, 2):
    plt.fill_between([x_simp[i], x_simp[i+2]], [0, 0], [y_simp[i], y_simp[i+2]], color='green', alpha=0.3, interpolate=True)
plt.title("Composite Simpson's Rule (20 subintervals)")
plt.xlabel('x')
plt.ylabel('sin(x)')
plt.legend()

plt.tight_layout()
plt.show()

# Convergence comment
print("\nComparison: The Composite Simpson's Rule provides a more accurate approximation than the Composite Trapezoidal Rule\n due to its higher order of accuracy (O(h^4) vs. O(h^2)).\n The absolute error for Simpson's rule is significantly lower, reflecting its better performance for this smooth function over 20 subintervals.")

#Q4)

import numpy as np
import matplotlib.pyplot as plt
from scipy import integrate

def f(x):
    return np.exp(-x**2)

# Exact value of the integral (approximated numerically since it's not elementary)
exact_value, _ = integrate.quad(f, 0, 1)

# Composite Trapezoidal Rule
def composite_trapezoidal(a, b, n):
    x = np.linspace(a, b, n + 1)
    y = f(x)
    h = (b - a) / n
    integral = (h / 2) * (y[0] + 2 * np.sum(y[1:-1]) + y[-1])
    return integral, x, y

# Parameters
a, b = 0, 1  # Integration limits
n1 = 100      # 100 subintervals
n2 = 200      # 200 subintervals

# Compute integrals
trap_result1, x_trap1, y_trap1 = composite_trapezoidal(a, b, n1)
trap_result2, x_trap2, y_trap2 = composite_trapezoidal(a, b, n2)

# Compute errors
error1 = abs(exact_value - trap_result1)
error2 = abs(exact_value - trap_result2)

# Print results
print(f"Exact Value (numerical): {exact_value:.10f}")
print(f"Trapezoidal Rule (100 subintervals): {trap_result1:.10f}, Absolute Error: {error1:.10f}")
print(f"Trapezoidal Rule (200 subintervals): {trap_result2:.10f}, Absolute Error: {error2:.10f}")

# Estimate order of accuracy
h1 = (b - a) / n1
h2 = (b - a) / n2
order = np.log(error2 / error1) / np.log(h2 / h1)
print(f"Estimated Order of Accuracy: {order:.4f} (Expected ~2 due to O(h^2))")

# Visualization
plt.figure(figsize=(12, 5))

# Plot 1: Function and Trapezoidal Approximation (100 subintervals)
plt.subplot(1, 2, 1)
plt.plot(x_trap1, y_trap1, label='e^(-x^2)', color='blue')
for i in range(len(x_trap1)-1):
    plt.fill_between([x_trap1[i], x_trap1[i+1]], [0, 0], [y_trap1[i], y_trap1[i+1]], color='lightblue', alpha=0.3)
plt.title('Composite Trapezoidal Rule (100 subintervals)')
plt.xlabel('x')
plt.ylabel('e^(-x^2)')
plt.legend()

# Plot 2: Function and Trapezoidal Approximation (200 subintervals)
plt.subplot(1, 2, 2)
plt.plot(x_trap2, y_trap2, label='e^(-x^2)', color='blue')
for i in range(len(x_trap2)-1):
    plt.fill_between([x_trap2[i], x_trap2[i+1]], [0, 0], [y_trap2[i], y_trap2[i+1]], color='lightblue', alpha=0.3)
plt.title('Composite Trapezoidal Rule (200 subintervals)')
plt.xlabel('x')
plt.ylabel('e^(-x^2)')
plt.legend()

plt.tight_layout()
plt.show()

#Q1)
import random
import numpy as np
import matplotlib.pyplot as plt

def analyze_dynamical_system(r, a0, num_terms=100):
    sequence = [a0]
    for n in range(num_terms - 1):
        a_n_plus_1 = (r**n) * a0
        sequence.append(a_n_plus_1)
    return sequence

num_a0_values = 10
num_r_per_case = 3
num_terms = 100

plt.style.use('ggplot')

for a0_idx in range(num_a0_values):
    curr_a0 = round(random.uniform(0.5, 1.0), 2)

    case_ii_r = [round(random.uniform(0, 1), 2) for _ in range(num_r_per_case)]
    case_iii_r = [round(random.uniform(-1, 0), 2) for _ in range(num_r_per_case)]
    case_iv_r = [round(random.expovariate(1), 2 ) for _ in range(num_r_per_case)]

    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)
    fig.suptitle(f'Dynamical System Analysis for a0 = {curr_a0}', fontsize=14, y=1.05)

    for i, (case_name, r_values, ax) in enumerate(zip(
        ['0 < r < 1', '-1 < r < 0', 'r > 0'],
        [case_ii_r, case_iii_r, case_iv_r],
        axes
    )):
        for r in r_values:
            sequence = analyze_dynamical_system(r, curr_a0, num_terms)
            ax.plot(sequence, '-o', label=f'r = {r}')

        ax.set_title(case_name)
        ax.set_xlabel('Term index (n)')
        ax.set_ylabel('Value (a_n)')
        ax.grid(True)
        ax.legend()

    plt.tight_layout()

#Q2)
import matplotlib.pyplot as plt

def calc_and_plot(dosage, color, label, num_terms=50):
    sequence = [0]
    for i in range(num_terms):
        c_n = sequence[-1]
        c_n_plus_1 = 0.5 * c_n + dosage
        sequence.append(c_n_plus_1)

    plt.plot(range(len(sequence)), sequence, color=color, marker='o',
             linestyle='-', linewidth=2, markersize=6, label=label)
    plt.xticks([i for i in range(num_terms+1)])

dosages = [0.1, 0.2, 0.3]
colors = ['purple', 'lightgreen', 'lightblue']
labels = [f'Dose = {d} mg' for d in dosages]

plt.figure(figsize=(10, 6))

for d, color, label in zip(dosages, colors, labels):
    calc_and_plot(d, color, label)

plt.title('Digoxin Concentration Over Time', fontsize=14, pad=10)
plt.xlabel('Day (n)', fontsize=12)
plt.ylabel('Concentration (mg)', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=10, numpoints=1)
plt.tight_layout()

plt.show()

#Q3)
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def plot_frequency_polygon(dist_name, data, size, bins=30):
    """Plot histogram and frequency polygon for a distribution"""
    plt.figure(figsize=(10, 6))

    counts, bin_edges = np.histogram(data, bins=bins, density=False)

    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])

    plt.hist(data, bins=bins, alpha=0.5, color='lightpink', edgecolor='navy', label='Histogram', density=True)

    bin_width = bin_edges[1] - bin_edges[0]
    heights = counts / (size * bin_width)

    plt.plot(bin_centers, heights, marker='o', color='purple', label='Frequency Polygon', linewidth=2)

    plt.title(f'{dist_name} Distribution (n={size})')
    plt.xlabel('Value')
    plt.ylabel('Frequency/Density')
    plt.legend()
    plt.grid(True)
    plt.show()

sample_sizes = [500, 1000, 10000, 100000]

for size in sample_sizes:
    uniform_data = np.random.uniform(0, 1, size=size)
    plot_frequency_polygon('Uniform', uniform_data, size)

    exp_data = np.random.exponential(scale=1, size=size)
    plot_frequency_polygon('Exponential', exp_data, size)

    weibull_data = np.random.weibull(a=1.5, size=size)
    plot_frequency_polygon('Weibull', weibull_data, size)

    triangular_data = np.random.triangular(left=0, mode=0.5, right=1, size=size)
    plot_frequency_polygon('Triangular', triangular_data, size)

#Q4 - PI value calculation

import numpy as np
import matplotlib.pyplot as plt

def estimate_pi(num_samples):
    x = np.random.uniform(0, 1, num_samples)
    y = np.random.uniform(0, 1, num_samples)

    inside_circle = (x**2 + y**2) <= 1
    pi_estimate = 4 * np.sum(inside_circle) / num_samples

    return pi_estimate, x, y, inside_circle

num_samples = 100000
pi_value, x, y, inside_circle = estimate_pi(num_samples)

plt.figure(figsize=(8, 8))
plt.scatter(x[inside_circle], y[inside_circle], color='green', s=1, label='Inside Circle')
plt.scatter(x[~inside_circle], y[~inside_circle], color='red', s=1, label='Outside Circle')
plt.title(f'Estimate of Pi = {pi_value:.4f}', fontsize=16)
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.xlim(0, 1)
plt.ylim(0, 1)
plt.gca().set_aspect('equal', adjustable='box')
plt.legend()
plt.grid()
plt.show()

#Q5
import numpy as np
import matplotlib.pyplot as plt
from tabulate import tabulate

PURCHASE_COST = 30
SALE_PRICE = 45
RECYCLE_VALUE = 5
STOCK_QUANTITY = 60
NEWS_CATEGORIES = ['Good', 'Normal', 'Poor']
CATEGORY_PROBS = [0.35, 0.45, 0.20]
CATEGORY_BOUNDS = [(1, 35), (36, 80), (81, 100)]

DEMAND_LEVELS = [40, 50, 60, 70, 80, 90, 100]
GOOD_DEMAND_BOUNDS = [(1, 3), (4, 8), (9, 23), (24, 43), (44, 78), (79, 93), (94, 100)]
NORMAL_DEMAND_BOUNDS = [(1, 10), (11, 28), (29, 68), (69, 88), (89, 96), (97, 100)]
POOR_DEMAND_BOUNDS = [(1, 44), (45, 66), (67, 82), (83, 94), (95, 100)]

def determine_news_category(rand_val):
    for idx, (lower, upper) in enumerate(CATEGORY_BOUNDS):
        if lower <= rand_val <= upper:
            return NEWS_CATEGORIES[idx]
    return NEWS_CATEGORIES[-1]

def assign_demand(category, rand_val):
    bounds = (
        GOOD_DEMAND_BOUNDS if category == 'Good' else
        NORMAL_DEMAND_BOUNDS if category == 'Normal' else
        POOR_DEMAND_BOUNDS
    )
    for idx, (lower, upper) in enumerate(bounds):
        if lower <= rand_val <= upper:
            return DEMAND_LEVELS[idx]
    return DEMAND_LEVELS[-1]

def compute_metrics(customer_demand, stock_available):
    units_sold = min(customer_demand, stock_available)

    sales_income = units_sold * SALE_PRICE

    unmet_demand = max(0, customer_demand - stock_available)
    missed_profit = unmet_demand * (SALE_PRICE - PURCHASE_COST)

    excess_stock = max(0, stock_available - units_sold)
    recycle_income = excess_stock * RECYCLE_VALUE

    total_cost = stock_available * PURCHASE_COST
    daily_profit = sales_income + recycle_income - total_cost

    return sales_income, missed_profit, recycle_income, daily_profit

def execute_simulation(total_days):
    np.random.seed(42)
    category_list = []
    demand_list = []
    income_list = []
    missed_profit_list = []
    recycle_list = []
    profit_list = []

    for _ in range(total_days):
        category_rand = np.random.randint(1, 101)
        news_category = determine_news_category(category_rand)
        category_list.append(news_category)

        if news_category == 'Good':
            demand_rand = int(np.random.exponential(scale=40)) % 100 + 1
        elif news_category == 'Normal':
            demand_rand = int(np.clip(np.random.normal(loc=50, scale=10), 0, 100)) + 1
        else:
            demand_rand = int(np.random.poisson(lam=50)) % 100 + 1

        demand = assign_demand(news_category, demand_rand)
        demand_list.append(demand)

        income, missed, recycle, profit = compute_metrics(demand, STOCK_QUANTITY)
        income_list.append(income)
        missed_profit_list.append(missed)
        recycle_list.append(recycle)
        profit_list.append(profit)

    return {
        'categories': category_list,
        'demands': demand_list,
        'incomes': income_list,
        'missed_profits': missed_profit_list,
        'recycles': recycle_list,
        'profits': profit_list,
        'avg_income': np.mean(income_list),
        'avg_missed': np.mean(missed_profit_list),
        'avg_recycle': np.mean(recycle_list),
        'avg_profit': np.mean(profit_list)
    }

def display_results():
    simulation_periods = [200, 500, 1000, 10000]

    for period in simulation_periods:
        print(f"\nResults for {period} Days Simulation")
        sim_results = execute_simulation(period)

        table_data = []
        for i in range(min(5, period)):
            sold = min(sim_results['demands'][i], STOCK_QUANTITY)
            table_data.append([
                i + 1,
                sim_results['categories'][i],
                sim_results['demands'][i],
                STOCK_QUANTITY,
                sold,
                f"{sim_results['incomes'][i]:.2f} cents",
                f"{sim_results['missed_profits'][i]:.2f} cents",
                f"{sim_results['recycles'][i]:.2f} cents",
                f"{sim_results['profits'][i]:.2f} cents"
            ])

        headers = ['Day', 'News Type', 'Demand', 'Bought', 'Sold', 'Sales Income', 'Missed Profit', 'Recycle Income', 'Daily Profit']
        print(tabulate(table_data, headers=headers, tablefmt='grid'))

        print(f"\nSummary Statistics:")
        print(f"Average Sales Income: {sim_results['avg_income']:.2f} cents")
        print(f"Average Missed Profit: {sim_results['avg_missed']:.2f} cents")
        print(f"Average Recycle Income: {sim_results['avg_recycle']:.2f} cents")
        print(f"Average Daily Profit: {sim_results['avg_profit']:.2f} cents")

        plt.figure(figsize=(12, 7))
        plt.plot(range(1, period + 1), sim_results['profits'], color='#ff7f0e', linestyle='-', label='Daily Earnings')
        plt.title(f'Earnings Trend for {period} Days')
        plt.xlabel('Day Number')
        plt.ylabel('Earnings ($)')
        plt.legend()
        plt.grid(True, linestyle='--', alpha=0.7)
        plt.show()

    np.random.seed(42)
    random_values = np.random.randint(1, 101, size=100)
    news_categories = [determine_news_category(val) for val in random_values]
    print("\nPart (a): 100 Random News Categories")
    print(news_categories)

    np.random.seed(42)
    good_demands = np.random.exponential(scale=40, size=100).astype(int)
    good_demands = np.clip(good_demands, 0, 100)
    normal_demands = np.random.normal(loc=50, scale=10, size=100).astype(int)
    normal_demands = np.clip(normal_demands, 0, 100)
    poor_demands = np.random.poisson(lam=50, size=100)
    poor_demands = np.clip(poor_demands, 0, 100)

    print("\nPart (b): Demand Values")
    print("Good News Demands (Exponential, mean=40):")
    print(good_demands)
    print("\nNormal News Demands (Normal, mean=50, sd=10):")
    print(normal_demands)
    print("\nPoor News Demands (Poisson, mean=50):")
    print(poor_demands)

if __name__ == "__main__":
    display_results()

#Q6
import numpy as np
import matplotlib.pyplot as plt
from collections import deque
from tabulate import tabulate

TOTAL_DURATION = 1000
AVG_ARRIVAL_GAP = 10
MIN_SERVICE_TIME = 8
MAX_SERVICE_TIME = 12
AVG_SERVICE_TIME = 10

ARRIVE = 'ARRIVE'
LEAVE = 'LEAVE'

def initialize_simulation():
    np.random.seed(42)
    event_schedule = []
    waiting_line = deque()
    system_status = []
    customer_wait_times = []
    clerk_occupied = False
    clerk_occupied_time = 0
    current_time = 0
    customer_counter = 0
    customers_in_system = 0
    arrival_records = {}

    first_arrival = np.random.exponential(AVG_ARRIVAL_GAP)
    event_schedule.append((first_arrival, ARRIVE, customer_counter))
    return (event_schedule, waiting_line, system_status, customer_wait_times,
            clerk_occupied, clerk_occupied_time, current_time, customer_counter,
            customers_in_system, arrival_records)

def handle_arrival(current_time, customer_id, event_schedule, waiting_line,
                  system_status, customer_wait_times, clerk_occupied,
                  customers_in_system, arrival_records):
    arrival_records[customer_id] = current_time
    customers_in_system += 1
    system_status.append((current_time, customers_in_system))

    if current_time < TOTAL_DURATION:
        next_id = customer_id + 1
        next_arrival = current_time + np.random.exponential(AVG_ARRIVAL_GAP)
        event_schedule.append((next_arrival, ARRIVE, next_id))

    if not clerk_occupied:
        clerk_occupied = True
        service_duration = np.random.poisson(AVG_SERVICE_TIME)
        service_duration = max(MIN_SERVICE_TIME, min(MAX_SERVICE_TIME, service_duration))
        customer_wait_times.append(0)
        event_schedule.append((current_time + service_duration, LEAVE, customer_id))
        return service_duration, clerk_occupied
    else:
        waiting_line.append(customer_id)
        return 0, clerk_occupied

def handle_departure(current_time, customer_id, event_schedule, waiting_line,
                     system_status, customer_wait_times, clerk_occupied,
                     customers_in_system, arrival_records, service_duration):
    customers_in_system -= 1
    system_status.append((current_time, customers_in_system))

    service_start = arrival_records[customer_id] if customer_id not in waiting_line else current_time - service_duration
    wait_time = service_start - arrival_records[customer_id]
    if wait_time > 0:
        customer_wait_times[-1] = wait_time
    del arrival_records[customer_id]

    if waiting_line:
        next_customer = waiting_line.popleft()
        new_service_duration = np.random.poisson(AVG_SERVICE_TIME)
        new_service_duration = max(MIN_SERVICE_TIME, min(MAX_SERVICE_TIME, new_service_duration))
        customer_wait_times.append(current_time - arrival_records[next_customer])
        event_schedule.append((current_time + new_service_duration, LEAVE, next_customer))
        return new_service_duration, True
    else:
        return 0, False

def run_queue_simulation():
    (event_schedule, waiting_line, system_status, customer_wait_times,
     clerk_occupied, clerk_occupied_time, current_time, customer_counter,
     customers_in_system, arrival_records) = initialize_simulation()

    event_log = []

    while event_schedule and current_time < TOTAL_DURATION:
        event_schedule.sort()
        time, event_type, cid = event_schedule.pop(0)
        current_time = time

        if len(event_log) < 5:
            event_log.append([current_time, event_type, cid, len(waiting_line), customer_wait_times[-1] if customer_wait_times else 0])

        if event_type == ARRIVE:
            service_duration, clerk_occupied = handle_arrival(
                current_time, cid, event_schedule, waiting_line, system_status,
                customer_wait_times, clerk_occupied, customers_in_system, arrival_records
            )
            clerk_occupied_time += service_duration
            customers_in_system += 1
            customer_counter += 1
        elif event_type == LEAVE:
            service_duration, clerk_occupied = handle_departure(
                current_time, cid, event_schedule, waiting_line, system_status,
                customer_wait_times, clerk_occupied, customers_in_system, arrival_records, service_duration
            )
            clerk_occupied_time += service_duration

    avg_wait = np.mean(customer_wait_times) if customer_wait_times else 0
    avg_queue_len = sum(wt * len(waiting_line) for wt in customer_wait_times) / TOTAL_DURATION if customer_wait_times else 0
    clerk_utilization = clerk_occupied_time / TOTAL_DURATION if TOTAL_DURATION > 0 else 0

    return {
        'system_status': system_status,
        'wait_times': customer_wait_times,
        'avg_wait': avg_wait,
        'avg_queue_len': avg_queue_len,
        'utilization': clerk_utilization,
        'event_log': event_log
    }

def display_simulation_results():
    results = run_queue_simulation()

    headers = ['Time (min)', 'Event Type', 'Customer ID', 'Queue Length', 'Wait Time (min)']
    print("\nFirst 5 Events in Simulation:")
    print(tabulate(results['event_log'], headers=headers, tablefmt='grid', floatfmt='.2f'))

    print(f"\nSimulation Summary:")
    print(f"Average Wait Time in Queue: {results['avg_wait']:.2f} minutes")
    print(f"Average Queue Length: {results['avg_queue_len']:.2f} customers")
    print(f"Clerk Utilization: {results['utilization']:.2%}")

    times, counts = zip(*results['system_status'])
    plt.figure(figsize=(10, 6))
    plt.step(times, counts, where='post', color='#2ca02c', label='Customers in System')
    plt.title('Queue System Dynamics Over Time')
    plt.xlabel('Time (minutes)')
    plt.ylabel('Number of Customers')
    plt.legend()
    plt.grid(True, linestyle=':', alpha=0.8)
    plt.show()

if __name__ == "__main__":
    display_simulation_results()

import matplotlib.pyplot as plt
import numpy as np

#Q1)

# input data
n = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
a_n = [3, 6, 11, 21, 32, 47, 65, 87, 112, 110, 171, 204, 241, 282, 325, 376]

delta_a_n = []

for i in range(1,len(n)):
  delta_a_n.append(a_n[i]-a_n[i-1])

print(delta_a_n)

n_delta = n[1:]

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(n_delta, delta_a_n, marker='o', linestyle='-', color='b')
plt.xlabel('n')
plt.ylabel('Îa_n')
plt.title('Changes Îa_n versus n')
plt.grid(True)
plt.show()

# Fit a quadratic model (a_n â k1*n^2 + k2*n + k3) using numpy polyfit
coefficients = np.polyfit(n, a_n, 2)  # Quadratic fit
a_n_pred = [coefficients[0] * n_i**2 + coefficients[1] * n_i + coefficients[2] for n_i in n]

# Calculate errors (actual - predicted)
errors = [a_n[i] - a_n_pred[i] for i in range(len(n))]

# Plot errors versus n
plt.figure(figsize=(10, 6))
plt.plot(n, errors, marker='o', linestyle='-', color='r')
plt.xlabel('n')
plt.ylabel('Error (a_n - a_n_pred)')
plt.title('Errors in Predicted Values versus n')
plt.grid(True)
plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)  # Reference line at zero error
plt.show()

# Print the difference equation model
print(f"Difference equation model (approximate): a_n â {coefficients[0]:.2f}n^2 + {coefficients[1]:.2f}n + {coefficients[2]:.2f}")

#Q2

import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

force = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])
stretch = np.array([19, 57, 94, 134, 173, 216, 256, 297, 343])

# Newton Forward Interpolation
def newton_forward_interpolation(x, y):
    n = len(x)
    h = x[1] - x[0]
    coef = np.zeros([n, n])
    coef[:, 0] = y

    for j in range(1, n):
        for i in range(n - j):
            coef[i][j] = coef[i + 1][j - 1] - coef[i][j - 1]

    def poly(t):
        s = (t - x[0]) / h
        result = coef[0][0]
        term = 1
        for j in range(1, n):
            term *= (s - (j - 1)) / j
            result += coef[0][j] * term
        return result

    return poly, coef[0]

interp_poly, forward_coeffs = newton_forward_interpolation(force, stretch)

force_fine = np.linspace(min(force), max(force), 200)
stretch_interp = [interp_poly(f) for f in force_fine]

forces_to_predict = [15, 17, 85]
stretch_predicted = [interp_poly(f) for f in forces_to_predict]

stretch_errors = [abs(interp_poly(f) - s) for f, s in zip(force, stretch)]

t_stat, p_value = stats.ttest_rel(stretch, [interp_poly(f) for f in force])

plt.figure(figsize=(12, 10))

plt.subplot(2, 1, 1)
plt.scatter(force, stretch, color='green', label='Actual Data', s=50)
plt.plot(force_fine, stretch_interp, color='blue', linestyle='-', linewidth=2, label='Newton Forward Interpolation')
plt.xlabel('Force')
plt.ylabel('Stretch')
plt.title('Stretch vs Force (Newton Forward Interpolation)')
plt.grid(True, alpha=0.3)
plt.legend()
for f, s in zip(forces_to_predict, stretch_predicted):
    plt.plot(f, s, 'ro', label= f'Stretch at Force {f} = {s:.2f}' if f == forces_to_predict[0] else "")
plt.legend()

plt.subplot(2, 1, 2)
plt.plot(force, stretch_errors, 'r-o', label='Absolute Error')
plt.xlabel('Force')
plt.ylabel('Absolute Error')
plt.title('Interpolation Error')
plt.grid(True, alpha=0.3)
plt.legend()

plt.tight_layout()
plt.show()

print("Interpolating Polynomial Coefficients (Newton Forward):", forward_coeffs)
print("\nPredicted Stretch Values:")
for f, s in zip(forces_to_predict, stretch_predicted):
    print(f"Force {f}: Stretch = {s:.2f}")
print(f"\nT-test Results: t-stat = {t_stat:.4f}, p-value = {p_value:.4f}")
print(f"Mean Absolute Error: {np.mean(stretch_errors):.6f}")

#Q3)

import numpy as np
import matplotlib.pyplot as plt

T = np.array([300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000])
e = np.array([0.024, 0.035, 0.046, 0.058, 0.067, 0.083, 0.097, 0.111, 0.125, 0.140, 0.155, 0.170, 0.186, 0.202, 0.219, 0.235, 0.252, 0.269])
x = (T - 300) / 100  # Normalizing temperature to start from 0

# Newton's Divided Difference Interpolation
def newton_divided_difference(x_vals, y_vals):
    n = len(x_vals)
    coef = np.zeros([n, n])
    coef[:, 0] = y_vals

    for j in range(1, n):
        for i in range(n - j):
            coef[i][j] = (coef[i + 1][j - 1] - coef[i][j - 1]) / (x_vals[i + j] - x_vals[i])

    def poly(t):
        result = coef[0][0]
        term = 1
        for j in range(1, n):
            term *= (t - x_vals[j - 1])
            result += coef[0][j] * term
        return result

    return poly, coef[0]

# Lagrange's Interpolation
def lagrange_interpolation(x_vals, y_vals):
    def poly(t):
        result = 0
        for i in range(len(x_vals)):
            term = y_vals[i]
            for j in range(len(x_vals)):
                if j != i:
                    term *= (t - x_vals[j]) / (x_vals[i] - x_vals[j])
            result += term
        return result

    return poly

ndd_poly, ndd_coeffs = newton_divided_difference(x, e)
lag_poly = lagrange_interpolation(x, e)

x_fine = np.linspace(min(x), max(x), 200)
e_ndd = [ndd_poly(xi) for xi in x_fine]
e_lag = [lag_poly(xi) for xi in x_fine]

x_points = [0.5, 3]
e_ndd_at_points = [ndd_poly(xp) for xp in x_points]
e_lag_at_points = [lag_poly(xp) for xp in x_points]

plt.figure(figsize=(12, 6))

plt.scatter(x, e, color='black', label='Original Data', s=30)
plt.plot(x_fine, e_ndd, color='red', linestyle='-', label='Newton Divided Difference')
plt.plot(x_fine, e_lag, color='blue', linestyle='--', label="Lagrange's Interpolation")
for xp, en, el in zip(x_points, e_ndd_at_points, e_lag_at_points):
    plt.plot(xp, en, 'ro', label=f'NDD at x={xp} = {en:.3f}' if xp == x_points[0] else "")
    plt.plot(xp, el, 'bo', label=f'Lagrange at x={xp} = {el:.3f}' if xp == x_points[0] else "")
plt.xlabel('Normalized Temperature (x = (T - 300) / 100)')
plt.ylabel('Emittance')
plt.title('Emittance vs Temperature (Interpolated)')
plt.grid(True, alpha=0.3)
plt.legend()

plt.tight_layout()
plt.show()

print("Newton Divided Difference Coefficients:", ndd_coeffs)
print("\nValues at x = 0.5 and x = 3:")
print(f"Newton Divided Difference: x=0.5 = {e_ndd_at_points[0]:.6f}, x=3 = {e_ndd_at_points[1]:.6f}")
print(f"Lagrange's Interpolation: x=0.5 = {e_lag_at_points[0]:.6f}, x=3 = {e_lag_at_points[1]:.6f}")

#Q4

import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d, CubicSpline

x = np.array([2, 2.5, 3, 3.5, 4])
y = np.array([1, np.sqrt(2) - 1, -1, np.sqrt(2) - 1, 1])

def true_function(x):
    return np.where(x >= 3, 2 * np.sqrt(x - 3) - 1, np.nan)

x_fine = np.linspace(2, 4, 200)

# Linear spline
linear_spline = interp1d(x, y, kind='linear', fill_value='extrapolate')
y_linear = linear_spline(x_fine)

# Cubic spline
cubic_spline = CubicSpline(x, y, extrapolate=True)
y_cubic = cubic_spline(x_fine)

# Polynomial interpolant (degree 4)
poly_coeffs = np.polyfit(x, y, 4)
y_poly = np.polyval(poly_coeffs, x_fine)

# Plot interpolants
plt.figure(figsize=(12, 8))
plt.plot(x, y, 's', color='purple', label='Data Points', markersize=10)
plt.plot(x_fine, y_linear, '-', color='teal', label='Linear Spline', linewidth=3)
plt.plot(x_fine, y_cubic, '--', color='gold', label='Cubic Spline', linewidth=3)
plt.plot(x_fine, y_poly, ':', color='red', label='Polynomial Interpolant', linewidth=3)
plt.plot(x_fine[x_fine >= 3], true_function(x_fine[x_fine >= 3]), 'k-', label='True Function (x >= 3)', linewidth=2)
plt.xlabel('x', fontsize=14, fontweight='bold')
plt.ylabel('y', fontsize=14, fontweight='bold')
plt.title('Interpolation Visualization', fontsize=16, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=12, loc='best')
plt.show()

# (b) Error computation at x = 2.125
x_eval = 2.125
true_val = true_function(x_eval)  # Will be nan since x < 3

y_linear_eval = linear_spline(x_eval)
y_cubic_eval = cubic_spline(x_eval)
y_poly_eval = np.polyval(poly_coeffs, x_eval)

true_val_approx = true_function(3)  # -1
error_linear = abs(true_val_approx - y_linear_eval) if not np.isnan(true_val_approx) else np.nan
error_cubic = abs(true_val_approx - y_cubic_eval) if not np.isnan(true_val_approx) else np.nan
error_poly = abs(true_val_approx - y_poly_eval) if not np.isnan(true_val_approx) else np.nan

print(f"True value at x = 2.125: {true_function(x_eval)} (undefined, using x=3 value: -1)")
print(f"Linear Spline Error (vs x=3): {error_linear:.6f}")
print(f"Cubic Spline Error (vs x=3): {error_cubic:.6f}")
print(f"Polynomial Error (vs x=3): {error_poly:.6f}")

x_refined = np.array([3, 3.25, 3.5, 3.75, 4])
y_refined = true_function(x_refined)  # Valid since x >= 3, no nan
linear_spline_refined = interp1d(x_refined, y_refined, kind='linear', fill_value='extrapolate')
cubic_spline_refined = CubicSpline(x_refined, y_refined, extrapolate=True)

y_linear_refined = linear_spline_refined(x_eval)
y_cubic_refined = cubic_spline_refined(x_eval)

error_linear_refined = abs(true_val_approx - y_linear_refined) if not np.isnan(true_val_approx) else np.nan
error_cubic_refined = abs(true_val_approx - y_cubic_refined) if not np.isnan(true_val_approx) else np.nan

print(f"\nRefined Interpolants at x = 2.125:")
print(f"Linear Spline Refined Error (vs x=3): {error_linear_refined:.6f}")
print(f"Cubic Spline Refined Error (vs x=3): {error_cubic_refined:.6f}")

# Convergence analysis (qualitative)
print("\nConvergence Analysis:")
print("Linear spline errors decrease with more points but are limited by piecewise linearity.")
print("Cubic spline errors decrease more due to C2 continuity, showing faster convergence.")
print(f"Original vs Refined Error Reduction - Linear: {error_linear - error_linear_refined:.6f}, Cubic: {error_cubic - error_cubic_refined:.6f}")

#Q5

temperature = [0, 8, 16, 24, 32, 40]
oxygen = [14.621, 11.843, 9.870, 8.418, 7.305, 6.413]
n = len(temperature) - 1

m = [0.0] * (n + 1)
h = [temperature[i + 1] - temperature[i] for i in range(n)]
alpha = [0.0] * n

for i in range(1, n):
    alpha[i] = (3.0 / h[i]) * (oxygen[i + 1] - oxygen[i]) - (3.0 / h[i - 1]) * (oxygen[i] - oxygen[i - 1])

l = [1.0]
u = [2.0 * (h[0] + h[1])]
z = [alpha[1]]

for i in range(1, n - 1):
    l.append(h[i] / u[i - 1])
    u.append(2.0 * (h[i] + h[i + 1]) - l[i] * h[i])
    z.append(alpha[i + 1] - l[i] * z[i - 1])

m[1] = z[-1] / u[-1]
for i in range(n - 2, 0, -1):
    m[i + 1] = (z[i] - h[i] * m[i + 2]) / u[i]

a = oxygen[:-1]
b = []
c = []
d = []

for i in range(n):
    hi = h[i]
    b.append((oxygen[i + 1] - oxygen[i]) / hi - hi * (2 * m[i] + m[i + 1]) / 6)
    c.append(m[i] / 2)
    d.append((m[i + 1] - m[i]) / (6 * hi))

def evaluate_spline(x_val):
    for i in range(n):
        if temperature[i] <= x_val <= temperature[i + 1]:
            dx = x_val - temperature[i]
            return a[i] + b[i] * dx + c[i] * dx**2 + d[i] * dx**3
    return None

t_fine = [t / 10 for t in range(int(temperature[0] * 10), int(temperature[-1] * 10) + 1)]
o2_fine = [evaluate_spline(t) for t in t_fine]

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(temperature, oxygen, 'o', label='Data Points', color='blue', markersize=8)
plt.plot(t_fine, o2_fine, '-', label='Cubic Spline', color='red', linewidth=2)
plt.xlabel('Temperature (Â°C)', fontsize=12, fontweight='bold')
plt.ylabel('Oxygen Concentration (mg/L)', fontsize=12, fontweight='bold')
plt.title('Cubic Spline Interpolation of Dissolved Oxygen vs Temperature', fontsize=14, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=10)
plt.show()

#Q6)

import numpy as np
import matplotlib.pyplot as plt

N_values = [2, 4, 6, 8, 12, 20]

plt.figure(figsize=(12, 8))

colors = ['b', 'g', 'r', 'c', 'm', 'y']

for idx, N in enumerate(N_values):
    x_points = [0] + [j / N for j in range(1, N + 1)]
    y_points = [1] + [0] * N


    coeffs = np.polyfit(x_points, y_points, N)

    x_fine = np.linspace(-1, 1, 200)
    p_x = np.polyval(coeffs, x_fine)

    plt.plot(x_fine, p_x, label=f'N = {N}', color=colors[idx % len(colors)], linewidth=2)

plt.plot(0, 1, 'ko', label='p_{2N}(0) = 1', markersize=8)
for N in N_values:
    for j in range(1, N + 1):
        x_j = j / N
        if -1 <= x_j <= 1:
            plt.plot(x_j, 0, 'kx', markersize=8)
plt.xlabel('x', fontsize=12, fontweight='bold')
plt.ylabel('p_{2N}(x)', fontsize=12, fontweight='bold')
plt.title('Polynomials p_{2N}(x) for Different N', fontsize=14, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=10)
plt.ylim(-1.5, 1.5)
plt.show()

print("Behavior of p_{2N}(x) as N increases:")
print("As N increases, the polynomial p_{2N}(x) exhibits more oscillations between the interpolation points (Runge's phenomenon). The polynomial starts at p_{2N}(0) = 1 and passes through zero at x = j/N for j = 1,...,N. With higher N, the degree increases (intended as 2N), leading to greater instability and larger deviations from the intended flat behavior outside the interpolation points, especially near the boundaries x = Â±1. This is due to the high-degree polynomial trying to fit the constraints, resulting in wild oscillations.")